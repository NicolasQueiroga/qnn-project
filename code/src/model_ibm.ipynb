{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from qiskit_ibm_provider import IBMProvider, least_busy\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import SamplerQNN, EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import random\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    provider = IBMProvider()\n",
    "except:\n",
    "    load_dotenv('../../.env')\n",
    "    IBMProvider.save_account(token=os.environ.get('IBMQ_TOKEN'))\n",
    "    provider = IBMProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "backend = provider.get_backend('ibmq_qasm_simulator')\n",
    "# backend = least_busy(\n",
    "#     provider.backends(\n",
    "#         simulator=False, filters=lambda b: b.configuration().n_qubits == 4\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "ROOT = os.path.join('..')\n",
    "data_dir = os.path.join(ROOT, 'input')\n",
    "images_dir = os.path.join(data_dir, 'Data')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "output_dir = os.path.join(ROOT, 'outputs')\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir) \n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "    \n",
    "os.makedirs(train_dir, exist_ok = True)\n",
    "os.makedirs(test_dir, exist_ok = True)\n",
    "os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "classes = os.listdir(images_dir)\n",
    "\n",
    "for c in classes:\n",
    "    class_dir = os.path.join(images_dir, c)\n",
    "    images = os.listdir(class_dir)\n",
    "       \n",
    "    n_train = int(len(images) * TRAIN_RATIO)\n",
    "    train_images = images[:n_train]\n",
    "    test_images = images[n_train:]\n",
    "    \n",
    "    os.makedirs(os.path.join(train_dir, c), exist_ok = True)\n",
    "    os.makedirs(os.path.join(test_dir, c), exist_ok = True)\n",
    "    \n",
    "    for image in train_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(train_dir, c, image) \n",
    "        shutil.copyfile(image_src, image_dst)\n",
    "        \n",
    "    for image in test_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(test_dir, c, image) \n",
    "        shutil.copyfile(image_src, image_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir, transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "    \n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 256\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds= [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.RandomHorizontalFlip(0.5),\n",
    "                           transforms.RandomCrop(pretrained_size, padding = 10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Resize(pretrained_size),\n",
    "                           transforms.CenterCrop(pretrained_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = train_dir, \n",
    "                                  transform = train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root = test_dir, \n",
    "                                 transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data, \n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_iterator = data.DataLoader(train_data, \n",
    "                                 shuffle = True, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = data.DataLoader(valid_data, \n",
    "                                 batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = data.DataLoader(test_data, \n",
    "                                batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, classes, normalize = True):\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        \n",
    "        image = images[i]\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_IMAGES = 25\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in \n",
    "                           [train_data[i] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = test_data.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qnn(output_dim):\n",
    "    feature_map = ZZFeatureMap(output_dim)\n",
    "    ansatz = RealAmplitudes(output_dim, reps=1)\n",
    "    qc = QuantumCircuit(output_dim)\n",
    "    qc.compose(feature_map, inplace=True)\n",
    "    qc.compose(ansatz, inplace=True)\n",
    "\n",
    "    # REMEMBER TO SET input_gradients=True FOR ENABLING HYBRID GRADIENT BACKPROP\n",
    "    qnn = EstimatorQNN(\n",
    "        circuit=qc,\n",
    "        input_params=feature_map.parameters,\n",
    "        weight_params=ansatz.parameters,\n",
    "        input_gradients=True,\n",
    "    )\n",
    "    return qnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetQNN(nn.Module):\n",
    "    def __init__(self, output_dim, is_qnn=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 16 * 16, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "        self.is_qnn = is_qnn\n",
    "        self.qantum_features = nn.Sequential(\n",
    "            TorchConnector(create_qnn(output_dim)),\n",
    "            nn.Linear(4, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        if self.is_qnn:\n",
    "            x = self.qantum_features(x)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_qnn = True\n",
    "if is_qnn:\n",
    "    MODEL_NAME = 'alexnet_qnn'\n",
    "else:\n",
    "    MODEL_NAME = 'alexnet'\n",
    "\n",
    "model = AlexNetQNN(len(classes), is_qnn=is_qnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_LR = 1e-7\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=START_LR)\n",
    "device = torch.device('mps')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinder:\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, 'init_params.pt'))\n",
    "\n",
    "    def range_test(self, iterator, end_lr = 10, num_iter = 100, smooth_f = 0.05, diverge_th = 5):\n",
    "        lrs = []\n",
    "        losses = []\n",
    "        best_loss = float('inf')\n",
    "        lr_scheduler = ExponentialLR(self.optimizer, end_lr, num_iter)\n",
    "        iterator = IteratorWrapper(iterator)\n",
    "        \n",
    "        for iteration in range(num_iter):\n",
    "            loss = self._train_batch(iterator)\n",
    "\n",
    "            lr_scheduler.step()\n",
    "            lrs.append(lr_scheduler.get_lr()[0])\n",
    "\n",
    "            if iteration > 0:\n",
    "                loss = smooth_f * loss + (1 - smooth_f) * losses[-1]          \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "            losses.append(loss)      \n",
    "            if loss > diverge_th * best_loss:\n",
    "                print(\"Stopping early, the loss has diverged\")\n",
    "                break\n",
    "                       \n",
    "        #reset model to initial parameters\n",
    "        model.load_state_dict(torch.load('init_params.pt'))\n",
    "                    \n",
    "        return lrs, losses\n",
    "\n",
    "    def _train_batch(self, iterator):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        x, y = iterator.get_batch()\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        y_pred, _ = self.model(x)      \n",
    "        loss = self.criterion(y_pred, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "class ExponentialLR(_LRScheduler):\n",
    "    def __init__(self, optimizer, end_lr, num_iter, last_epoch=-1):\n",
    "        self.end_lr = end_lr\n",
    "        self.num_iter = num_iter\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        curr_iter = self.last_epoch + 1\n",
    "        r = curr_iter / self.num_iter\n",
    "        return [base_lr * (self.end_lr / base_lr) ** r for base_lr in self.base_lrs]\n",
    "\n",
    "class IteratorWrapper:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self._iterator = iter(iterator)\n",
    "\n",
    "    def __next__(self):\n",
    "        try:\n",
    "            inputs, labels = next(self._iterator)\n",
    "        except StopIteration:\n",
    "            self._iterator = iter(self.iterator)\n",
    "            inputs, labels, *_ = next(self._iterator)\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def get_batch(self):\n",
    "        return next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "END_LR = 10\n",
    "NUM_ITER = 100\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.range_test(train_iterator, END_LR, NUM_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_finder(lrs, losses, skip_start = 5, skip_end = 5):\n",
    "    \n",
    "    if skip_end == 0:\n",
    "        lrs = lrs[skip_start:]\n",
    "        losses = losses[skip_start:]\n",
    "    else:\n",
    "        lrs = lrs[skip_start:-skip_end]\n",
    "        losses = losses[skip_start:-skip_end]\n",
    "    \n",
    "    fig = plt.figure(figsize = (16,8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(lrs, losses)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Learning rate')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.grid(True, 'both', 'x')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lr_finder(lrs, losses, skip_start = 30, skip_end = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOUND_LR = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "STEPS_PER_EPOCH = len(train_iterator)\n",
    "TOTAL_STEPS = EPOCHS * STEPS_PER_EPOCH\n",
    "\n",
    "MAX_LRS = [p['lr'] for p in optimizer.param_groups]\n",
    "\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                    max_lr = MAX_LRS,\n",
    "                                    total_steps = TOTAL_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, _ = model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, device):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), os.path.join(output_dir, f'{MODEL_NAME}.pt'))\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
